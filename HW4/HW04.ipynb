{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(667346304)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsim = 1000\n",
    "n = 100\n",
    "lambda = 0.3\n",
    "\n",
    "# save all estimated variance in a vector\n",
    "allridgebeta = matrix(NA, nsim, 1)\n",
    "\n",
    "for i in range(1:nsim):\n",
    "    # Setting the covariance between X_1 and X_2 to 0.9\n",
    "    X = mvrnorm(n, c(0, 0), matrix(c(1, 0.9, 0.9, 1), 2, 2))\n",
    "    y = rnorm(n, mean = X[, 1] + X[, 2])\n",
    "    # Saving the first parameter beta1\n",
    "    betas=solve(t(X) %*% X + lambda * n * diag(2)) %*% t(X) %*% y\n",
    "    allridgebeta[i] = betas[1]\n",
    "\n",
    "# For 1000 simulations, we obtain 1000 beta1 estimated values\n",
    "dim(allridgebeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Mean of beta1 estimates\n",
    "colMeans(allridgebeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Comparing mean of beta1 estimates with truth value=1 - calculating the Bias\n",
    "colMeans(allridgebeta)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Variance of beta1 estimates\n",
    "apply(allridgebeta, 2, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed to UIN\n",
    "set.seed(667346304)\n",
    "nsim = 1000\n",
    "n = 100\n",
    "lambda_grid = seq(0, 0.5, length.out = 100)\n",
    "# save estimated variance for first parameter in a vector\n",
    "allridgebeta = matrix(NA, nsim, 100)\n",
    "for (index in 1:length(lambda_grid)) { for (i in 1:nsim)\n",
    "{\n",
    "# create highly correlated variables and a linear model # Setting the covariance between X1 and X2 to 0.9.\n",
    "X = mvrnorm(n, c(0, 0), matrix(c(1, 0.9, 0.9, 1), 2, 2)) y = rnorm(n, mean = X[, 1] + X[, 2])\n",
    "    # Saving the first parameter beta1 at each nsim\n",
    "    betas = solve(t(X) %*% X + lambda_grid[index] *\n",
    "\n",
    "n * diag(2)) %*% t(X) %*% y\n",
    "    allridgebeta[i, index] = betas[1]\n",
    "} }\n",
    "# Mean of beta1 estimates\n",
    "colMeans(allridgebeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias of beta1 estimates\n",
    "bias_values=colMeans(allridgebeta)-1\n",
    "# Variance of beta1 estimates\n",
    "variance_values = apply(allridgebeta, 2, var)\n",
    "variance_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Length of bias_values vector\n",
    "length(bias_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of variance_values vector\n",
    "length(variance_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a plot of three quantities over each of your ùúÜ values: Bias2, Variance, and Bias2 + Variance. \n",
    "#Hence there should be three curves over the range of lambda from 0 to 0.5. \n",
    "bias_square=bias_values^2\n",
    "bias_square_plus_variance=(bias_values^2)+variance_values\n",
    "df=data.frame(lambda_grid,bias_square,variance_values,bias_square_plus_variance)\n",
    "library(ggplot2)\n",
    "ggplot(df, aes(x=lambda_grid)) +\n",
    "  geom_line(aes(y = bias_square, color= \"bias_square\")) +\n",
    "  geom_line(aes(y = variance_values, color= \"variance_values\")) +\n",
    "  geom_line(aes(y = bias_square_plus_variance,color= \"bias_square_plus_variance\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value of lambda where bias_square_plus_variance is minimum\n",
    "lambda_grid[which.min(bias_square_plus_variance)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross-validation code using lm.ridge()\n",
    "library(MASS)\n",
    "testing_error = matrix(NA, 100, 5)\n",
    "avg_testing_error = rep(NA, 100)\n",
    "lambda_seq = seq(1, 100, length.out = 100)\n",
    "# Making folds of 7,6,6,6,7\n",
    "folds <- cut(seq(1,nrow(mtcars)),breaks=5,labels=FALSE)\n",
    "for (k in 1:5) {\n",
    "testIndexes <- which(folds==k,arr.ind=TRUE) #print(testIndexes)\n",
    "test <- mtcars[testIndexes, ]\n",
    "train <- mtcars[-testIndexes, ]\n",
    "  train_data=train[,-c(1)]\n",
    "  fit1 = lm.ridge(train$mpg ~ .,\n",
    "                  data = train_data,\n",
    "                  lambda = seq(1, 100, length.out = 100))\n",
    "  # fit1 = lm.ridge(mpg ~ .,\n",
    "  #                 data = train,\n",
    "  #                 lambda = seq(1, 100, length.out = 100))\n",
    "  ## add intercept column, remove mpg column\n",
    "  test_data = cbind(1, test)\n",
    "  test_data = test_data[-c(2)]\n",
    "for (i in 1:100) {\n",
    "# predict on the testing data\n",
    "y_pred = data.matrix(test_data) %*% coef(fit1)[i,] # For each k, obtaining the testing error testing_error[i, k] = mean((y_pred - test$mpg) ^ 2)\n",
    "} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Average all K testing errors\n",
    "    avg_testing_error = apply(testing_error, 1, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to show how cross-validation error changes over different lambda\n",
    "plot(\n",
    "  lambda_seq,\n",
    "  avg_testing_error,\n",
    "  type = \"l\",\n",
    "  col = \"darkorange\",\n",
    "  ylab = \"CV Error\",\n",
    "  xlab = \"Lambda\",\n",
    "  lwd = 3\n",
    ")\n",
    "title(\"mtcars Data: K-fold CV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best penalty level obtained using the 5-fold cross-validation\n",
    "lambda_seq[which.min(avg_testing_error)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing that with the GCV result\n",
    " plot(fit1$lambda[1:100], fit1$GCV[1:100], type = \"l\", col = \"darkorange\",\n",
    "         ylab = \"GCV\", xlab = \"Lambda\", lwd = 3)\n",
    "    title(\"mtcars Data: GCV\")\n",
    "    \n",
    "fit1$lambda[which.min(fit1$GCV)]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cv.glmnet() from the glmnet package to perform a 5-fold cross-validation\n",
    "library(glmnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(667346304)\n",
    "fit2 = cv.glmnet(\n",
    "  x = data.matrix(mtcars[,-1]),\n",
    "  y = mtcars$mpg,\n",
    "  nfolds = 5,\n",
    "  alpha = 0\n",
    ")\n",
    "#Plottingcross-validationerroragainst values\n",
    "plot(fit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # lambda.min value\n",
    "fit2$lambda.min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # lambda.1se value\n",
    "fit2$lambda.1se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
